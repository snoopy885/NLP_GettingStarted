{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "863d2afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a9d95c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"nlp-getting-started/train.csv\")\n",
    "test_df = pd.read_csv(\"nlp-getting-started/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be82f3b",
   "metadata": {},
   "source": [
    "#### Data quick look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2920de64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love fruits'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"target\"] == 0][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be4b175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forest fire near La Ronge Sask. Canada'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df[\"target\"] == 1][\"text\"].values[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f15db5",
   "metadata": {},
   "source": [
    "## Building Vectors\n",
    "我們將在這個筆記本中構建的模型背後的理論非常簡單：\n",
    "每條推文中包含的單詞是它們是否與真正的災難有關的良好指標（這並不完全正確，但這是一個很好的起點）。\n",
    "\n",
    "我們將使用scikit-learn的CountVectorizer來計算每條推文中的單詞，並將其轉化為我們的機器學習模型可以處理的資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5b69ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "\n",
    "## let's get counts for the first 5 tweets in the data\n",
    "example_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b4a42f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 54)\n",
      "[[0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "## we use .todense() here because these vectors are \"sparse\" (only non-zero elements are kept to save space)\n",
    "print(example_train_vectors[0].todense().shape)\n",
    "print(example_train_vectors[0].todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5323fb",
   "metadata": {},
   "source": [
    "The above tells us that:<br>\n",
    "\n",
    "1. There are 54 unique words (or \"tokens\") in the first five tweets.<br>\n",
    "2. The first tweet contains only some of those unique tokens - all of the non-zero counts above are the tokens that DO exist in the first tweet.\n",
    "\n",
    "Now let's create vectors for all of our tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f1875d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4da6887",
   "metadata": {},
   "source": [
    "請注意，我們這裡沒有使用 .fit_transform( )。 僅使用 .transform( ) 可以確保訓練向量中的token是唯一對應到測試向量的 token，即訓練和測試向量使用相同的 token set。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95f985",
   "metadata": {},
   "source": [
    "## Model\n",
    "正如我們上面提到的，我們認為每條推文中包含的單詞是衡量它們是否與真正的災難有關的良好指標。 \n",
    "推文中特定單詞（或一組單詞）的存在可能會直接關聯到該推文是否真實。\n",
    "\n",
    "我們在這裡假設的是線性的。 所以讓我們建立一個線性模型！\n",
    "\n",
    "Our vectors are really big, so we want to push our model's weights toward 0 without completely discounting different words - ridge regression is a good way to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7afdc081",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.RidgeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c764d09",
   "metadata": {},
   "source": [
    "讓我們測試一下我們的模型，看看它在訓練資料上做得如何。 \n",
    "為此，我們將使用交叉驗證——我們對已知資料的一部分進行訓練，然後與其他資料一起驗證。 如果我們這樣做幾次（使用不同的部分），我們可以很好地瞭解特定模型或方法的執行情況。\n",
    "這場比賽的指標是F1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "013b2a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59453669, 0.56455572, 0.64113893])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397fde24",
   "metadata": {},
   "source": [
    "上述分數並不糟糕！ 看起來我們的假設在排行榜上得分約為0.65。 有很多方法可以對此進行潛在改進（TFIDF、LSA、LSTM/RNN，清單很長！）-給他們中的任何一個機會！\n",
    "\n",
    "與此同時，讓我們對我們的訓練集進行預測，併為比賽建立一個提交材料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c797ee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
